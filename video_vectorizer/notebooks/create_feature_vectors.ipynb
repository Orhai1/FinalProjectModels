{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MuspTB8oBIBL"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KcHwHD0zCAoS"
      },
      "outputs": [],
      "source": [
        "%cd /content/drive/MyDrive/video_vectorizer/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1WzouGHfC6e2",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics\n",
        "!pip install -q insightface onnxruntime-gpu\n",
        "!pip install easyocr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gUfC0-zDCzx9",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import files\n",
        "import tqdm\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from main_vectorizer import vectorize_video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4UbdClkfCd23",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "X_list = []\n",
        "y_list = []\n",
        "feature_names = None\n",
        "\n",
        "# Constants\n",
        "FRAMES_ROOT = \"/content/drive/MyDrive/all_videos_frames/\"\n",
        "CSV_PATH = \"classification_summary.csv\"\n",
        "MANIFEST_PATH = \"processed.json\"\n",
        "OUT_DIR = \"features\"\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "# Load Metadata\n",
        "meta_df = pd.read_csv(CSV_PATH, dtype=str).fillna('')\n",
        "label_map = dict(zip(meta_df.video_id, meta_df.final_classification))\n",
        "music_map = dict(zip(meta_df.video_id, meta_df.music_id))\n",
        "username_map = dict(zip(meta_df.video_id, meta_df.username))\n",
        "description_map = dict(zip(meta_df.video_id, meta_df.description))\n",
        "\n",
        "# Video Folders\n",
        "video_dirs = sorted(os.listdir(FRAMES_ROOT))\n",
        "video_dirs = [d for d in video_dirs if os.path.isdir(os.path.join(FRAMES_ROOT, d))]\n",
        "\n",
        "# Load/Create manifest\n",
        "if os.path.exists(MANIFEST_PATH):\n",
        "    processed = set(json.load(open(MANIFEST_PATH)))\n",
        "    print(f\"{len(processed)} videos already done\")\n",
        "else:\n",
        "    processed = set()\n",
        "\n",
        "# Process a folder of video frames\n",
        "def vectorize_vid(folder_name, video_id):\n",
        "    frames_path = os.path.join(FRAMES_ROOT, folder_name)\n",
        "\n",
        "    if video_id not in label_map:\n",
        "        return None\n",
        "\n",
        "    description = description_map.get(video_id, \"\")\n",
        "    username = username_map.get(video_id, \"\")\n",
        "    music_id = music_map.get(video_id, \"\")\n",
        "\n",
        "    try:\n",
        "        vector, feature_names = vectorize_video(\n",
        "            frames_path,\n",
        "            description,\n",
        "            username,\n",
        "            music_id\n",
        "        )\n",
        "        return (vector, label_map[video_id], feature_names)\n",
        "    except Exception as e:\n",
        "        print(f\"[{video_id}] Error: {e}\")\n",
        "        return None\n",
        "\n",
        "# Loop over all videos, process and save them\n",
        "for folder in tqdm.tqdm(video_dirs, desc=\"vectorizing\"):\n",
        "    if folder in processed:\n",
        "        continue # skip already processed videos\n",
        "\n",
        "    video_id = folder.replace(\"_frames\", \"\")\n",
        "    result = vectorize_vid(folder, video_id)\n",
        "    if result is None:\n",
        "        continue\n",
        "\n",
        "    vector, label, feat_names = result\n",
        "    out_path = f\"{OUT_DIR}/{folder}.npz\"\n",
        "\n",
        "    # atomic 1-file-per-video save\n",
        "    np.savez_compressed(\n",
        "      f\"{OUT_DIR}/{folder}.npz\",\n",
        "      X=vector,\n",
        "      y=np.array([label]),\n",
        "      feature_names=np.array(feat_names),\n",
        "      video_id=np.array([video_id])\n",
        "    )\n",
        "\n",
        "    # update manifest on Drive\n",
        "    processed.add(folder)\n",
        "    with open(MANIFEST_PATH, \"w\") as jf:\n",
        "        json.dump(list(processed), jf)\n",
        "\n",
        "print(f\"Done. {len(processed)}/{len(video_dirs)} videos processed.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "\n",
        "FEATURE_DIR   = \"features\"\n",
        "OUT_NPZ       = \"all_features.npz\"\n",
        "OUT_PARQUET   = \"all_features.parquet\"\n",
        "\n",
        "Xs, ys, ids = [], [], []\n",
        "\n",
        "# Gather all per-video file\n",
        "for path in glob.glob(f\"{FEATURE_DIR}/*.npz\"):\n",
        "    d = np.load(path)\n",
        "    Xs.append(d[\"X\"])          # shape (feature_dim,)\n",
        "    ys.append(d[\"y\"])          # shape (1,)\n",
        "    ids.append(d[\"video_id\"])  # shape (1,)\n",
        "\n",
        "# Merge into one big table\n",
        "X_all   = np.vstack(Xs)            # (N, feature_dim)\n",
        "y_all   = np.hstack(ys)            # (N,)\n",
        "ids_all = np.hstack(ids)           # (N,)\n",
        "\n",
        "print(\"Merged:\", X_all.shape, y_all.shape, ids_all.shape)\n",
        "\n",
        "# Save in npx format\n",
        "np.savez_compressed(OUT_NPZ,\n",
        "                    X=X_all,\n",
        "                    y=y_all,\n",
        "                    video_id=ids_all)\n",
        "\n",
        "# Save as Parquet table\n",
        "df = pd.DataFrame(X_all, columns=[f\"f{i}\" for i in range(X_all.shape[1])])\n",
        "df.insert(0, \"video_id\", ids_all)\n",
        "df.insert(1, \"label\",    y_all)\n",
        "df.to_parquet(OUT_PARQUET, compression=\"zstd\")\n",
        "\n",
        "# Download final tables\n",
        "files.download(OUT_NPZ)\n",
        "files.download(OUT_PARQUET)\n"
      ],
      "metadata": {
        "id": "AbMhl0HVecPE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "private_outputs": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}