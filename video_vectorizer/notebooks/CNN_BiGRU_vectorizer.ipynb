{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as T\n",
        "from torchvision.models import resnet50\n",
        "from torchvision.io import read_image"
      ],
      "metadata": {
        "id": "UA6sL2vgxInI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(DEVICE)"
      ],
      "metadata": {
        "id": "RJ4AmTlLxLku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def frozen_resnet50():\n",
        "    model = resnet50(weights=\"IMAGENET1K_V2\")\n",
        "    model.fc = torch.nn.Identity()          # 2048-d\n",
        "    for p in model.parameters():\n",
        "        p.requires_grad_(False)\n",
        "    return model.to(DEVICE).eval()\n",
        "\n",
        "PREPROC = T.Compose([\n",
        "    T.Resize(256),\n",
        "    T.CenterCrop(224),\n",
        "    T.ConvertImageDtype(torch.float32),\n",
        "    T.Normalize([0.485, 0.456, 0.406],\n",
        "                [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "def load_frames(frames_dir, n_frames=32, pad_to_len=None):\n",
        "    paths = sorted(Path(frames_dir).glob(\"*.jpg\"))\n",
        "    if not paths:\n",
        "        return torch.empty(0, 3, 224, 224, device=DEVICE)\n",
        "\n",
        "    # samples up to n_frames, if the video has more frames will downsample uniformly\n",
        "    idx = np.linspace(0, len(paths) - 1,\n",
        "                      num=min(n_frames, len(paths)),\n",
        "                      dtype=int)\n",
        "    batch = torch.stack([PREPROC(read_image(str(paths[i])))\n",
        "                         for i in idx]).to(DEVICE)\n",
        "\n",
        "    # Optional: repeat last frame until pad_to_len\n",
        "    if pad_to_len and batch.shape[0] < pad_to_len:\n",
        "        reps = pad_to_len - batch.shape[0]\n",
        "        batch = torch.cat([batch,\n",
        "                           batch[-1:].expand(reps, -1, -1, -1)], dim=0)\n",
        "    return batch"
      ],
      "metadata": {
        "id": "kRCOouQbxM8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FrameCNNBiGRUVectorizer:\n",
        "    def __init__(self, n_frames=32, hidden=384):\n",
        "        self.n_frames = n_frames\n",
        "        self.backbone = frozen_resnet50()\n",
        "        self.gru = nn.GRU(\n",
        "            input_size=2048,\n",
        "            hidden_size=hidden,\n",
        "            num_layers=1,\n",
        "            batch_first=True,\n",
        "            bidirectional=True\n",
        "        ).to(DEVICE)\n",
        "\n",
        "    @torch.inference_mode()\n",
        "    def vectorize_vid(self, frames_dir):\n",
        "        frames = load_frames(frames_dir,\n",
        "                             n_frames=self.n_frames,\n",
        "                             pad_to_len=None)\n",
        "        if frames.nelement() == 0:\n",
        "            return np.zeros(2 * self.gru.hidden_size, np.float32)\n",
        "\n",
        "        feats = self.backbone(frames)                        # (T,2048)\n",
        "        feats = feats.unsqueeze(0)                           # (1,T,2048)\n",
        "        _, h = self.gru(feats)                               # h: (2,1,H)\n",
        "        h = h.transpose(0, 1).reshape(1, -1)                 # (1, 2H)\n",
        "        return h.squeeze(0).cpu().numpy().astype(np.float32)\n"
      ],
      "metadata": {
        "id": "LyH-Wo1PwxlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Ho0KXwRj3f53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm.notebook as tq"
      ],
      "metadata": {
        "id": "WGP3oZCL4L1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def iter_frame_dirs(frames_root: Path):\n",
        "    \"\"\"\n",
        "    Yields (video_id, frames_dir) for every sub-directory whose name ends with\n",
        "    '_frames'.\n",
        "    \"\"\"\n",
        "    for p in sorted(frames_root.iterdir()):\n",
        "        if p.is_dir() and p.name.endswith(\"_frames\"):\n",
        "            yield p.name.rsplit(\"_frames\", 1)[0], p\n",
        "\n",
        "\n",
        "def save_vector(vec: np.ndarray, video_id: str, out_dir: Path):\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "    np.save(out_dir / f\"{video_id}_bigru.npy\", vec.astype(np.float32))\n"
      ],
      "metadata": {
        "id": "3vXeESND38ov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_bigru_extraction(frames_root: str,\n",
        "                         output_dir: str,\n",
        "                         n_frames: int = 32,\n",
        "                         hidden: int = 384):\n",
        "\n",
        "    frames_root = Path(frames_root)\n",
        "    output_dir  = Path(output_dir)\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    frame_dirs = [p for p in frames_root.iterdir()\n",
        "                  if p.is_dir() and p.name.endswith('_frames')]\n",
        "    vectoriser = FrameCNNBiGRUVectorizer(n_frames=n_frames, hidden=hidden)\n",
        "\n",
        "    for fdir in tq.tqdm(frame_dirs, desc='Extracting', unit='vid'):\n",
        "        video_id = fdir.name.rsplit('_frames', 1)[0]\n",
        "        vec = vectoriser.vectorize_vid(fdir)\n",
        "        np.save(output_dir / f'{video_id}_bigru.npy', vec.astype(np.float32))\n",
        "\n",
        "    print(f' Done. Wrote {len(frame_dirs)} vectors to {output_dir}')\n"
      ],
      "metadata": {
        "id": "q3lR2yNN3qv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frames_dir = \"/content/drive/MyDrive/all_videos_frames\"\n",
        "output_dir = \"/content/drive/MyDrive/video_vectorizer/cnn_output\"\n",
        "run_bigru_extraction(frames_dir, output_dir)"
      ],
      "metadata": {
        "id": "QEIdstrz5f-u"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}